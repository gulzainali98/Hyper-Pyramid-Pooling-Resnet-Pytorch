{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ResnetHPP.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "uH2qxMWjWtIJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "'''ResNet in PyTorch.\n",
        "\n",
        "For Pre-activation ResNet, see 'preact_resnet.py'.\n",
        "\n",
        "Reference:\n",
        "[1] Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun\n",
        "    Deep Residual Learning for Image Recognition. arXiv:1512.03385\n",
        "'''\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion*planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(self.expansion*planes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.conv3 = nn.Conv2d(planes, self.expansion*planes, kernel_size=1, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion*planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(self.expansion*planes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = F.relu(self.bn2(self.conv2(out)))\n",
        "        out = self.bn3(self.conv3(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, num_blocks, num_classes=10):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.in_planes = 64\n",
        "        print(\"init resnet\")\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
        "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
        "        self.linear = nn.Linear(512*block.expansion, num_classes)\n",
        "        self.linearHPP = nn.Linear(256, num_classes)\n",
        "        self.downsample=nn.Conv2d(2048, 256, kernel_size=1, stride=1, bias=False)\n",
        "        self.maxpool1=nn.MaxPool2d((4,4), stride=1)\n",
        "        self.maxpool2=nn.MaxPool2d((2,4), stride=1)\n",
        "\n",
        "    def _make_layer(self, block, planes, num_blocks, stride):\n",
        "        strides = [stride] + [1]*(num_blocks-1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_planes, planes, stride))\n",
        "            self.in_planes = planes * block.expansion\n",
        "        return nn.Sequential(*layers)\n",
        "      \n",
        "    def HPP(self,out):\n",
        "#         Hyper Pyramid Pooling Layer.\n",
        "#         Pooling to get G\n",
        "        pool11= F.avg_pool2d(out,4)+self.maxpool1(out)\n",
        "        pool21= F.avg_pool2d(out[:,:,0:2,:],(2,4))+self.maxpool2(out[:,:,0:2,:])\n",
        "        pool22= F.avg_pool2d(out[:,:,2:4,:],(2,4))+self.maxpool2(out[:,:,2:4,:])\n",
        "#         Downsampling the dimensions from 2048 to 256 to get H\n",
        "      \n",
        "        H22=self.downsample(pool22)\n",
        "        H11=self.downsample(pool11)\n",
        "        H21= self.downsample(pool21)\n",
        "      \n",
        "#     Flattening out the H for final classication\n",
        "        flattened22=H22.view(H22.size(0),-1)\n",
        "        flattened21=H21.view(H21.size(0),-1)\n",
        "        flattened11=H11.view(H11.size(0),-1)\n",
        "      \n",
        "#       Concatenating the results for final output\n",
        "        finalOutput=torch.cat((self.linearHPP(flattened11),self.linearHPP(flattened21),self.linearHPP(flattened22)),0)\n",
        "        \n",
        "        return finalOutput\n",
        "      \n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        return self.HPP(out)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def ResNet18():\n",
        "    return ResNet(BasicBlock, [2,2,2,2])\n",
        "\n",
        "def ResNet34():\n",
        "    return ResNet(BasicBlock, [3,4,6,3])\n",
        "\n",
        "def ResNet50():\n",
        "    return ResNet(Bottleneck, [3,4,6,3])\n",
        "\n",
        "def ResNet101():\n",
        "    return ResNet(Bottleneck, [3,4,23,3])\n",
        "\n",
        "def ResNet152():\n",
        "    return ResNet(Bottleneck, [3,8,36,3])\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UvAwAHhkRRLV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3502
        },
        "outputId": "e98171e4-21fa-48a0-bae2-c604c87df1f7"
      },
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torch.backends.cudnn as cudnn\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import os\n",
        "import argparse\n",
        "\n",
        "\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "best_acc = 0  # best test accuracy\n",
        "start_epoch = 0  # start from epoch 0 or last checkpoint epoch\n",
        "\n",
        "# Data\n",
        "print('==> Preparing data..')\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "batchsize=32\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batchsize, shuffle=True, num_workers=2)\n",
        "\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "# Model\n",
        "print('==> Building model..')\n",
        "net = ResNet50()\n",
        "\n",
        "net = net.to(device)\n",
        "if device == 'cuda':\n",
        "    net = torch.nn.DataParallel(net)\n",
        "    cudnn.benchmark = True\n",
        "    \n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9, weight_decay=5e-4)\n",
        "\n",
        "# Training\n",
        "def train(epoch):\n",
        "    print('\\nEpoch: %d' % epoch)\n",
        "    net.train()\n",
        "    train_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    it=0\n",
        "    max_accuracy=0\n",
        "    final_loss=0\n",
        "    \n",
        "    net.train()\n",
        "\n",
        "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
        "\n",
        "        it=it+1\n",
        "        \n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = net(inputs)\n",
        "        batch=(targets.size())[0]\n",
        "        if(batch<32):\n",
        "          print(batch)\n",
        "          print(outputs.size())\n",
        "        HPPTargets=torch.cat((targets,targets,targets),0)\n",
        "\n",
        "        loss=criterion(outputs[0:batch],targets)\n",
        "\n",
        "        for i in range(0,2):\n",
        "          loss= loss+ criterion(outputs[batch*(i+1):batch+(batch*(i+1))],targets)\n",
        "\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        train_loss += loss.item()\n",
        "        \n",
        "        _, predicted = outputs.max(1)\n",
        "        total += HPPTargets.size(0)\n",
        "        correct += predicted.eq(HPPTargets).sum().item()\n",
        "        \n",
        "        batch_total=HPPTargets.size(0)\n",
        "        batch_correct= predicted.eq(HPPTargets).sum().item()\n",
        "        batch_accuracy= 100.*batch_correct/batch_total\n",
        "        final_loss=train_loss/(batch_idx+1)\n",
        "        \n",
        "        if batch_accuracy>max_accuracy:\n",
        "          max_accuracy=batch_accuracy\n",
        "\n",
        "    print('Loss: %.3f | Max Batch Accuracy: %.3f | Epoch Accuracy : (%.3f)'% (final_loss, max_accuracy , 100.*correct/total))\n",
        "        \n",
        "        \n",
        "\n",
        "\n",
        "\n",
        "for epoch in range(0,40):\n",
        "  \n",
        "  train(epoch)\n",
        "  \n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==> Preparing data..\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "==> Building model..\n",
            "init resnet\n",
            "\n",
            "Epoch: 0\n",
            "16\n",
            "torch.Size([48, 10])\n",
            "Loss: 5.345 | Max Batch Accuracy: 71.875 | Epoch Accuracy : (33.685)\n",
            "\n",
            "Epoch: 1\n",
            "16\n",
            "torch.Size([48, 10])\n",
            "Loss: 3.831 | Max Batch Accuracy: 82.292 | Epoch Accuracy : (54.220)\n",
            "\n",
            "Epoch: 2\n",
            "16\n",
            "torch.Size([48, 10])\n",
            "Loss: 3.000 | Max Batch Accuracy: 91.667 | Epoch Accuracy : (65.224)\n",
            "\n",
            "Epoch: 3\n",
            "16\n",
            "torch.Size([48, 10])\n",
            "Loss: 2.435 | Max Batch Accuracy: 93.750 | Epoch Accuracy : (72.051)\n",
            "\n",
            "Epoch: 4\n",
            "16\n",
            "torch.Size([48, 10])\n",
            "Loss: 2.078 | Max Batch Accuracy: 96.875 | Epoch Accuracy : (76.365)\n",
            "\n",
            "Epoch: 5\n",
            "16\n",
            "torch.Size([48, 10])\n",
            "Loss: 1.823 | Max Batch Accuracy: 96.875 | Epoch Accuracy : (79.515)\n",
            "\n",
            "Epoch: 6\n",
            "16\n",
            "torch.Size([48, 10])\n",
            "Loss: 1.635 | Max Batch Accuracy: 100.000 | Epoch Accuracy : (81.506)\n",
            "\n",
            "Epoch: 7\n",
            "16\n",
            "torch.Size([48, 10])\n",
            "Loss: 1.484 | Max Batch Accuracy: 100.000 | Epoch Accuracy : (83.265)\n",
            "\n",
            "Epoch: 8\n",
            "16\n",
            "torch.Size([48, 10])\n",
            "Loss: 1.371 | Max Batch Accuracy: 100.000 | Epoch Accuracy : (84.549)\n",
            "\n",
            "Epoch: 9\n",
            "16\n",
            "torch.Size([48, 10])\n",
            "Loss: 1.263 | Max Batch Accuracy: 100.000 | Epoch Accuracy : (85.850)\n",
            "\n",
            "Epoch: 10\n",
            "16\n",
            "torch.Size([48, 10])\n",
            "Loss: 1.170 | Max Batch Accuracy: 100.000 | Epoch Accuracy : (86.699)\n",
            "\n",
            "Epoch: 11\n",
            "16\n",
            "torch.Size([48, 10])\n",
            "Loss: 1.080 | Max Batch Accuracy: 100.000 | Epoch Accuracy : (87.747)\n",
            "\n",
            "Epoch: 12\n",
            "16\n",
            "torch.Size([48, 10])\n",
            "Loss: 1.017 | Max Batch Accuracy: 100.000 | Epoch Accuracy : (88.594)\n",
            "\n",
            "Epoch: 13\n",
            "16\n",
            "torch.Size([48, 10])\n",
            "Loss: 0.941 | Max Batch Accuracy: 100.000 | Epoch Accuracy : (89.438)\n",
            "\n",
            "Epoch: 14\n",
            "16\n",
            "torch.Size([48, 10])\n",
            "Loss: 0.893 | Max Batch Accuracy: 100.000 | Epoch Accuracy : (89.816)\n",
            "\n",
            "Epoch: 15\n",
            "16\n",
            "torch.Size([48, 10])\n",
            "Loss: 0.838 | Max Batch Accuracy: 100.000 | Epoch Accuracy : (90.435)\n",
            "\n",
            "Epoch: 16\n",
            "16\n",
            "torch.Size([48, 10])\n",
            "Loss: 0.799 | Max Batch Accuracy: 100.000 | Epoch Accuracy : (90.768)\n",
            "\n",
            "Epoch: 17\n",
            "16\n",
            "torch.Size([48, 10])\n",
            "Loss: 0.755 | Max Batch Accuracy: 100.000 | Epoch Accuracy : (91.345)\n",
            "\n",
            "Epoch: 18\n",
            "16\n",
            "torch.Size([48, 10])\n",
            "Loss: 0.719 | Max Batch Accuracy: 100.000 | Epoch Accuracy : (91.744)\n",
            "\n",
            "Epoch: 19\n",
            "16\n",
            "torch.Size([48, 10])\n",
            "Loss: 0.688 | Max Batch Accuracy: 100.000 | Epoch Accuracy : (92.062)\n",
            "\n",
            "Epoch: 20\n",
            "16\n",
            "torch.Size([48, 10])\n",
            "Loss: 0.645 | Max Batch Accuracy: 100.000 | Epoch Accuracy : (92.615)\n",
            "\n",
            "Epoch: 21\n",
            "16\n",
            "torch.Size([48, 10])\n",
            "Loss: 0.630 | Max Batch Accuracy: 100.000 | Epoch Accuracy : (92.723)\n",
            "\n",
            "Epoch: 22\n",
            "16\n",
            "torch.Size([48, 10])\n",
            "Loss: 0.587 | Max Batch Accuracy: 100.000 | Epoch Accuracy : (93.225)\n",
            "\n",
            "Epoch: 23\n",
            "16\n",
            "torch.Size([48, 10])\n",
            "Loss: 0.562 | Max Batch Accuracy: 100.000 | Epoch Accuracy : (93.487)\n",
            "\n",
            "Epoch: 24\n",
            "16\n",
            "torch.Size([48, 10])\n",
            "Loss: 0.545 | Max Batch Accuracy: 100.000 | Epoch Accuracy : (93.532)\n",
            "\n",
            "Epoch: 25\n",
            "16\n",
            "torch.Size([48, 10])\n",
            "Loss: 0.516 | Max Batch Accuracy: 100.000 | Epoch Accuracy : (94.121)\n",
            "\n",
            "Epoch: 26\n",
            "16\n",
            "torch.Size([48, 10])\n",
            "Loss: 0.496 | Max Batch Accuracy: 100.000 | Epoch Accuracy : (94.253)\n",
            "\n",
            "Epoch: 27\n",
            "16\n",
            "torch.Size([48, 10])\n",
            "Loss: 0.478 | Max Batch Accuracy: 100.000 | Epoch Accuracy : (94.473)\n",
            "\n",
            "Epoch: 28\n",
            "16\n",
            "torch.Size([48, 10])\n",
            "Loss: 0.454 | Max Batch Accuracy: 100.000 | Epoch Accuracy : (94.767)\n",
            "\n",
            "Epoch: 29\n",
            "16\n",
            "torch.Size([48, 10])\n",
            "Loss: 0.424 | Max Batch Accuracy: 100.000 | Epoch Accuracy : (95.069)\n",
            "\n",
            "Epoch: 30\n",
            "16\n",
            "torch.Size([48, 10])\n",
            "Loss: 0.421 | Max Batch Accuracy: 100.000 | Epoch Accuracy : (95.193)\n",
            "\n",
            "Epoch: 31\n",
            "16\n",
            "torch.Size([48, 10])\n",
            "Loss: 0.400 | Max Batch Accuracy: 100.000 | Epoch Accuracy : (95.435)\n",
            "\n",
            "Epoch: 32\n",
            "16\n",
            "torch.Size([48, 10])\n",
            "Loss: 0.398 | Max Batch Accuracy: 100.000 | Epoch Accuracy : (95.387)\n",
            "\n",
            "Epoch: 33\n",
            "16\n",
            "torch.Size([48, 10])\n",
            "Loss: 0.381 | Max Batch Accuracy: 100.000 | Epoch Accuracy : (95.631)\n",
            "\n",
            "Epoch: 34\n",
            "16\n",
            "torch.Size([48, 10])\n",
            "Loss: 0.372 | Max Batch Accuracy: 100.000 | Epoch Accuracy : (95.699)\n",
            "\n",
            "Epoch: 35\n",
            "16\n",
            "torch.Size([48, 10])\n",
            "Loss: 0.341 | Max Batch Accuracy: 100.000 | Epoch Accuracy : (96.027)\n",
            "\n",
            "Epoch: 36\n",
            "16\n",
            "torch.Size([48, 10])\n",
            "Loss: 0.342 | Max Batch Accuracy: 100.000 | Epoch Accuracy : (96.021)\n",
            "\n",
            "Epoch: 37\n",
            "16\n",
            "torch.Size([48, 10])\n",
            "Loss: 0.329 | Max Batch Accuracy: 100.000 | Epoch Accuracy : (96.193)\n",
            "\n",
            "Epoch: 38\n",
            "16\n",
            "torch.Size([48, 10])\n",
            "Loss: 0.326 | Max Batch Accuracy: 100.000 | Epoch Accuracy : (96.227)\n",
            "\n",
            "Epoch: 39\n",
            "16\n",
            "torch.Size([48, 10])\n",
            "Loss: 0.295 | Max Batch Accuracy: 100.000 | Epoch Accuracy : (96.569)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}